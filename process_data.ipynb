{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use this notebook\n",
    "\n",
    "**Before running this notebook:**\n",
    "<br>\n",
    "Set up the following file structure (namely, the `raw/`, `processed/`, and `archive/` folders within `data/`). Populate `raw/` with the data that we have been given (shown below). \n",
    "\n",
    "```\n",
    "data/\n",
    "├── raw/\n",
    "│   ├── district.json\n",
    "│   ├── 2024-09-11_District_A_Benchmarks.json\n",
    "│   ├── 2024-09-11_District_A_Scores.json\n",
    "│   ├── 2024-09-11 District A Vendor Student Usage.json\n",
    "│   ├── vendorProducts_202409111049.csv\n",
    "│   └── ... (future raw data files)\n",
    "├── processed/\n",
    "└── archive/\n",
    "README.md\n",
    "```\n",
    "\n",
    "**When you run this notebook, it will...**\n",
    "- Rename the raw files to follow a consistent format\n",
    "- Pull out each individual table \n",
    "- Save each table as a `.csv` in `/data/processed`\n",
    "\n",
    "All names will be formatted as follows: `[district]_[table]_[date].[extension]`\n",
    "- e.g. `a_all_2024-09-11.json`\n",
    "- e.g. `a_scores_2024-09-11.csv`\n",
    "\n",
    "**After running this notebook:**\n",
    "<br>\n",
    "You can import tables indiviudally by using `pd.read_csv()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_path = os.path.join(repo_root, 'predicting-proficiency', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    ('2024-09-11 District A Benchmarks.json', 'a_benchmarks_2024-09-11.json'),\n",
    "    ('2024-09-11 District A Scores.json', 'a_scores_2024-09-11.json'),\n",
    "    ('2024-09-11 District A Vendor Student Usage.json', 'a_vendorUsage_2024-09-11.json'),\n",
    "    ('district.json', 'a_all_2024-08-29.json'),\n",
    "    ('vendorProducts_202409111049.csv', 'a_vendorKey_2024-09-11.csv')\n",
    "]\n",
    "\n",
    "for old_name, new_name in file_names:\n",
    "    old_path = os.path.join(data_path, 'raw', old_name)\n",
    "    new_path = os.path.join(data_path, 'raw', new_name)\n",
    "    if os.path.exists(old_path) and not os.path.exists(new_path):\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/a_all_2024-08-29.json', 'r') as file:\n",
    "    data = json.loads(file.read())\n",
    "\n",
    "with open('data/raw/a_scores_2024-09-11.json', 'r') as file:\n",
    "    scores_json = json.loads(file.read())\n",
    "\n",
    "with open('data/raw/a_benchmarks_2024-09-11.json', 'r') as file:\n",
    "    benchmarks_json = json.loads(file.read())\n",
    "\n",
    "with open('data/raw/a_vendorUsage_2024-09-11.json', 'r') as file:\n",
    "    vendorUsage_json = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving .csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_data = scores_json[list(scores_json.keys())[0]]\n",
    "scores_df = pd.DataFrame(scores_data)\n",
    "\n",
    "benchmarks_df = pd.DataFrame(benchmarks_json['benchmarks'])\n",
    "schools_df = pd.DataFrame(data['schools'])\n",
    "courseSections_df = pd.DataFrame(data['courseSections'])\n",
    "courseSectionRosters_df = pd.DataFrame(data['courseSectionRosters'])\n",
    "\n",
    "vendorUsage_data = vendorUsage_json[list(vendorUsage_json.keys())[0]]\n",
    "vendorUsage_df = pd.DataFrame(vendorUsage_data)\n",
    "\n",
    "vendorKey_df = pd.read_csv('data/raw/a_vendorKey_2024-09-11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(repo_root, 'predicting-proficiency', 'data')\n",
    "\n",
    "processed_dir = os.path.join(data_path, 'processed')\n",
    "if os.path.exists(processed_dir):\n",
    "    for file in os.listdir(processed_dir):\n",
    "        file_path = os.path.join(processed_dir, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.unlink(file_path)\n",
    "\n",
    "os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "benchmarks_df.to_csv(os.path.join(data_path, 'processed', 'a_benchmarks_2024-09-11.csv'), index=False)\n",
    "schools_df.to_csv(os.path.join(data_path, 'processed', 'a_schools_2024-08-29.csv'), index=False)\n",
    "courseSections_df.to_csv(os.path.join(data_path, 'processed', 'a_courseSections_2024-08-29.csv'), index=False)\n",
    "courseSectionRosters_df.to_csv(os.path.join(data_path, 'processed', 'a_courseSectionRosters_2024-08-29.csv'), index=False)\n",
    "scores_df.to_csv(os.path.join(data_path, 'processed', 'a_scores_2024-09-11.csv'), index=False)\n",
    "vendorUsage_df.to_csv(os.path.join(data_path, 'processed', 'a_vendorUsage_2024-09-11.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can stop here! The rest of the notebook is just flagging issues in the data that need to be resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We currently have two DataFrames with info on vendors: `vendorUsage_df` which contains usage stats with numerical ids for each vendor, and `vendorKey_df` which is a lookup table containing the name and id of each vendor. We will merge the two and export it as a single csv.\n",
    "\n",
    "Actually we won't yet because the ids don't match up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendorUsage_df = vendorUsage_df.merge(\n",
    "#     vendorKey_df[['vendorId', 'productName']], \n",
    "#     on='vendorId', \n",
    "#     how='left'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72609, 11333, 39195, 27172, 61673, 37017, 36130, 62382, 62509,\n",
       "       62508, 37269, 25405, 52447, 52448, 61544,  7273, 63431, 63432,\n",
       "       22410, 63616, 23165,  7035, 11464])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendorUsage_df['vendorId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11361, 21186, 21143, 11333, 13895, 11272, 11179, 72615, 14726,\n",
       "       72616, 72617, 72606, 72618, 72619, 14617, 13793, 72622, 11464,\n",
       "       14026, 11281])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vendorKey_df['vendorId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vendorIds in vendorUsage with no key: 21\n",
      "VendorIds with no key: {np.int64(63616), np.int64(22410), np.int64(37269), np.int64(37017), np.int64(39195), np.int64(72609), np.int64(36130), np.int64(27172), np.int64(62508), np.int64(62509), np.int64(62382), np.int64(25405), np.int64(63431), np.int64(63432), np.int64(52447), np.int64(52448), np.int64(61544), np.int64(61673), np.int64(7273), np.int64(7035), np.int64(23165)}\n"
     ]
    }
   ],
   "source": [
    "set1 = set(vendorUsage_df['vendorId'].unique())\n",
    "set2 = set(vendorKey_df['vendorId'].unique())\n",
    "\n",
    "missing_keys = set1 - set2\n",
    "num_missing = len(missing_keys)\n",
    "\n",
    "print(f\"Number of vendorIds in vendorUsage with no key: {num_missing}\")\n",
    "print(f\"VendorIds with no key: {missing_keys}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
